<!DOCTYPE html>




<html class="theme-next gemini" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>
<meta name="theme-color" content="#222">

<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>








<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/kitty_bbook_32x32.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/kitty_bbook_16x16.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="basic dl models,论文笔记," />










<meta name="description" content="基础DL模型 Spatial Transformer Networks 论文笔记">
<meta name="keywords" content="basic dl models,论文笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="基础DL模型-STN-Spatial Transformer Networks-论文笔记">
<meta property="og:url" content="https://arleyzhang.github.io/articles/7c7952f0/index.html">
<meta property="og:site_name" content="arleyzhang">
<meta property="og:description" content="基础DL模型 Spatial Transformer Networks 论文笔记">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517381763710.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517313809413.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517389003270.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517390080627.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517390143003.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517391663142.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517390161398.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517390173934.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517390244077.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517393808097.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517398935580.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517398970784.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517400545429.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517401679000.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517401798196.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/20170403231241311.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517402932968.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/678029-20151022183134552-279360383.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517403846718.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/678029-20151023135057427-1219705201.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517407970094.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517409630548.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517410123817.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517411239599.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517412959220.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517414543432.png">
<meta property="og:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517414970818.png">
<meta property="og:updated_time" content="2018-11-16T14:46:55.603Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="基础DL模型-STN-Spatial Transformer Networks-论文笔记">
<meta name="twitter:description" content="基础DL模型 Spatial Transformer Networks 论文笔记">
<meta name="twitter:image" content="https://arleyzhang.github.io/articles/7c7952f0/1517381763710.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://arleyzhang.github.io/articles/7c7952f0/"/>





  <title>基础DL模型-STN-Spatial Transformer Networks-论文笔记 | arleyzhang</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">arleyzhang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://arleyzhang.github.io/articles/7c7952f0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="arleyzhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="arleyzhang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">基础DL模型-STN-Spatial Transformer Networks-论文笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-05T02:26:46+08:00">
                2018-06-05
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-11-16T22:46:55+08:00">
                2018-11-16
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index">
                    <span itemprop="name">deep learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/articles/7c7952f0/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="articles/7c7952f0/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 浏览
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>次
            </span>
          

          

          
              <div class="post-description">
                  基础DL模型 Spatial Transformer Networks 论文笔记
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>论文：<a href="https://arxiv.org/abs/1506.02025" target="_blank" rel="external">Spatial Transformer Networks</a>，是Google旗下 DeepMind 公司的研究成果。</p>
<p>这篇论文的试验做的特别好。</p>
<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h1><h2 id="1-2-问题提出"><a href="#1-2-问题提出" class="headerlink" title="1.2 问题提出"></a>1.2 问题提出</h2><p>CNN在图像分类中取得了显著的成效，主要是得益于 CNN 的深层结构具有 空间不变性（spatially invariance）（平移不变性，旋转不变性），所以图像上的目标物体就算是做了平移或者旋转，CNN仍然能够准确的识别出来，这对于CNN的泛化能力是有益的。</p>
<ul>
<li>空间不变性主要是由于 Pooling 层 和 步长不为1的卷积层 的存在带来的。实际上主要是池化层的作用，因为大部分的卷积层的步长都是大于1而又小于卷积核大小的，也就是滑动时是有重叠的，而池化层一般不是重叠的。也就是说这些层越多，越深，池化核或卷积核越大，空间不变性也越强；但是随之而来的问题是局部信息丢失，所以这些层越多准确率肯定是下降的，所以主流的CNN分类网络一般都很深，但是池化核都比较小，比如2×2。</li>
<li>比如ResNet，GoogLeNet，VGG，FCN，这些网络的总降采样比例一般是 16或32，基本没有见过 64倍，128倍或者更高倍数的降采样（会损失局部信息降低准确率），也很少见到 2倍或者4倍的降采样比例（空间不变性太弱，泛化能力不好）。不过这个是跟数据集中的图像大小有关的，上述主流图像分类网络基本都是针对于 ImageNet数据集做分类的，ImageNet中的图片都比较大，一般在 256×256 左右。如果数据集中的图像本来就很小，那么降采样比例就也会小，比如 MNIST数据集，图像只有28×28，所以LeNet中的降采样比例是4。总之，降采样比例要根据数据集调整，找到合适的降采样比例，才能保证准确率的情况下，有较强的空间不变性。</li>
</ul>
<p>那么如何在保证准确率的情况下，即不损失局部信息的前提下，增强网络的空间不变性呢？这篇文章就是为了解决这个问题。</p>
<h2 id="1-2-解决方法"><a href="#1-2-解决方法" class="headerlink" title="1.2 解决方法"></a>1.2 解决方法</h2><p>对于CNN 来说，即便通过选择合适的降采样比例来保证准确率和空间不变性，但是 池化层 带来的空间不变性是不够的，它受限于预先选定的固定尺寸的池化核（感受野是固定的，局部的）。因为物体的变形包括旋转，平移，扭曲，缩放，混淆噪声等，所以后面feature map中像素点的感受野不一定刚好包含物体或者反映物体的形变。</p>
<p>文章提出了一种 Spatial Transformer Networks，简称 STN，引进了一种可学习的采样模块 Spatial Transformer ，姑且称为空间变换器，Spatial Transformer的学习不需要引入额外的数据标签，它可以在网络中对数据（feature map）进行空间变换操作。这个模块是可微的（后向传播必须），并且可以插入到现有的CNN模型中，使得 feature map具有空间变换能力，也就是说 感受野是动态变化的，feature map的空间变换方向 与 原图片上的目标的空间变换方向（一般认为是数据噪声）是相反的，所以使得整个网络的空间不变性增强。试验结果展示这种方法确实增强了空间不变性，在一些标志性的数据集（benchmark）上取得了先进的水平。</p>
<p><img src="/articles/7c7952f0/1517381763710.png" alt="1517381763710"></p>
<center><strong>图1 在输入层使用 Spatial Transformer</strong> </center>



<p>空说无凭，先看一个简单效果，如图1：</p>
<ul>
<li>(a) ：输入图片</li>
<li>(b) ：框起来的是用于后面网络进行进一步识别分类的部分，这一部分是就是Spatial Transformer的结果</li>
<li>(c) ：输出层的可视化</li>
<li>(d) ：预测结果</li>
</ul>
<p>整体上来看是一种视觉 attention 机制，也更像一种弱的目标检测机制，就是把图片中物体所在区域送到网络后面的层中，使得后面的分类任务更简单。</p>
<p><strong>CNN是尽力让网络适应物体的形变，而STN是直接通过  Spatial Transformer 将形变的物体给变回到正常的姿态（比如把字摆正），然后再给网络识别。</strong></p>
<p>文章给的 Spatial Transformer 的使用场景：</p>
<ul>
<li>image classification ：如果数据集中的图像上的目标形变很大，噪声很大，位于图片中心较远，那么  Spatial Transformer 可以将物体部分 “剪裁” 出来，并做一定的旋转，缩放变换，使之成为大小统一的图片，便于后续网络识别，并且获得比CNN更好的结果。</li>
<li>co-localisation ：给定输入图片，不确定是否有物体，如果有，可以使用Spatial Transformer做出定位。</li>
<li>spatial attention ：对于使用attention机制的视觉任务，可以很轻松的使用 Spatial Transformer 完成。</li>
</ul>
<p>看完这篇论文之后，个人觉得目标检测（object detection）也是可以用的，果不其然，真有人将类似的方法用在了 目标检测上，这篇论文就是 Deformable Convolutional Networks ，后面再讲。</p>
<h1 id="2-Spatial-Transformer结构"><a href="#2-Spatial-Transformer结构" class="headerlink" title="2 Spatial Transformer结构"></a>2 Spatial Transformer结构</h1><p>文章最重要的一个结构就是 Spatial Transformers ，这个结构的示意图如下：</p>
<p><img src="/articles/7c7952f0/1517313809413.png" alt="1517313809413"></p>
<center> <strong>图2 Spatial Transformers 结构图</strong></center>

<p>这样一个结构相当于 CNN中的一个 卷积层或者池化层：</p>
<p>这个结构又被分为三部分：localisation network ，grid generator和sampler</p>
<p>一些符号意义：</p>
<ul>
<li>$U \in R^{H \times W \times C}$ 为输入 feature map</li>
<li>$V \in R^{H’ \times W’ \times C’}$ 为输出 feature map</li>
<li>$\theta=f_{loc}(U)$  是一个回归子网络</li>
<li>$T_{\theta}$ 表示以参数 $\theta$ 为变换矩阵的某种变换，可以是2维仿射变换(2D affine transformation )，平面投影变换(plane projective transformation )，薄板样条变换(thin plate spline )</li>
<li>$ G_i = (x^t_i, y_i^t)$  代表V中的像素点   $G = \{G_i\} $ 是V中像素点的整体。</li>
<li>$T_{\theta}(G)$ 代表下面图3中，输入U上的绿色区域的坐标。</li>
</ul>
<p>这个图与图1做个对应，U 相当于 图1 中的 (a) , V相当于 图1 中的(c)，中间那一部分相当于图1 中的(b), 作用就是为了找到那个物体所在的框，或者叫做弱目标检测。</p>
<h2 id="2-1-Localisation-network"><a href="#2-1-Localisation-network" class="headerlink" title="2.1 Localisation network"></a>2.1 Localisation network</h2><p>这一部分很简单，可以使用全连接层或者全卷积层，只要保证最后一层是一个回归层即可，最后输出的一个向量是 $\theta$ 。 $\theta$ 的维度下面再说。</p>
<h2 id="2-2-Grid-generator"><a href="#2-2-Grid-generator" class="headerlink" title="2.2 Grid generator"></a>2.2 Grid generator</h2><p>前面提到中间那一部分是为了<strong>找到那个物体所在的框，并把它给 变换回 “直立的状态”</strong>。很自然就能想到使用仿射变换就可以完成，如下图：</p>
<p><img src="/articles/7c7952f0/1517389003270.png" alt="1517389003270"></p>
<center> <strong>图3 (a)恒等变换与采样； (b)仿射变换与采样</strong></center>

<p><strong>我们期望的是输出 V 是 将U中某一部分（比如绿色点覆盖的部分）做了旋转，放缩，平移之后的feature map。</strong></p>
<p>看一下Grid generator是如何进行仿射变换的。</p>
<hr>
<p>先简单的看一下仿射变换：</p>
<p>仿射变换用于表示旋转，缩放和平移，表示的是两副图之间的关系，</p>
<p>以下 A 为旋转矩阵，B 为平移矩阵，M称为仿射变换矩阵。</p>
<p><img src="/articles/7c7952f0/1517390080627.png" alt="1517390080627"></p>
<p><img src="/articles/7c7952f0/1517390143003.png" alt="1517390143003"></p>
<p>假设要对二维向量<img src="/articles/7c7952f0/1517391663142.png" alt="1517391663142">  进行仿射变换，仿射变换可以写成如下两式，两种写法等价：</p>
<p><img src="/articles/7c7952f0/1517390161398.png" alt="1517390161398"></p>
<p><img src="/articles/7c7952f0/1517390173934.png" alt="1517390173934"></p>
<p>输出的结果是：</p>
<p><img src="/articles/7c7952f0/1517390244077.png" alt="1517390244077"></p>
<p>对于仿射变换来说，一般的用法有两种：</p>
<ul>
<li>已知 M 和 X，求T; 这个很简单，直接矩阵相乘。</li>
<li>已知 X 和 T , 求M; 可以选取三对点，带入上面的式子中，列方程，6个方程6个未知数；</li>
</ul>
<hr>
<p>这里使用的是第一种用法。其中 图3 (b)  U 中的被绿点覆盖的那一部分相当于这里的 T，V相当于这里的 X，那不是应该 M也是已知的吗？M哪去了？还记得上面提到的 $\theta$ ？ $\theta$ 就相当于这里的M。因为 M的大小是 2×3 ，所以 $\theta$ 的维度为6。如果使用了别的变换方法，那就根据变换矩阵的大小相应调整。也就是说这里的变换矩阵是学习出来的。</p>
<p>对应于图3的变换公式如下：</p>
<p><img src="/articles/7c7952f0/1517393808097.png" alt="1517393808097"></p>
<ul>
<li>$(x^t_i, y_i^t)$  are the <strong>target coordinates</strong> of the  regular grid in the output feature map ，代表的是图3输出V中的像素点，即目标像素坐标；</li>
<li>$(x^s_i, y_i^s)$ are the <strong>source coordinates</strong> in the input feature map that define the sample points ,代表的是图3输入U中被绿色点覆盖的像素点，即源像素坐标；</li>
<li>$A_{\theta}$ is the affine transformation matrix ，代表的是仿射变换矩阵。其中的成员 $\theta_{ij}$ 由 localisation network 回归生成。图3或图2中的 $T_{\theta}$ 这时指的仿射变换 $A_{\theta}$。</li>
</ul>
<p>注意他这个仿射变换是  <strong>从后向前变换的</strong>，就是说这个模块的输出是仿射变换的输入，这个模块的输入的其中一部分（图3(b) 绿点覆盖部分）是仿射变换的输出。</p>
<p>按照一般的做法，应该是从前往后变换，即从 source coordinates 得到 target coordinates 。但是这样做的问题是，如何确定变换的输入？如果是从前往后做变换，U 中绿色部分相当于 X，那怎么确定这一部分是多大，什么形状，位置在哪？</p>
<p>实际上从后往前变换也就是为了解决这个问题，就是要根据输出V的坐标得到输入U中目标所在的区域的坐标（绿色的区域）。</p>
<p>仿射变换变换的是坐标，既是坐标，那么变换的输入和输出的坐标的参考系应该是一样的，就是说 V 中像素的坐标 和 U 中像素的坐标应该是同一个参考系。这里使用的是针对 宽和高 进行的归一化坐标(height and width normalised coordinates)，把在U和V中的像素坐标归一化到 [-1,1] 之间。U的 尺寸是上一层决定的，V的尺寸是人为固定的，输出 $H’,W’$  可以分别比 输入$H,W$ 大或者小，或者相等。</p>
<p>可以给仿射变换的变换矩阵添加更多的约束：</p>
<p><img src="/articles/7c7952f0/1517398935580.png" alt="1517398935580"></p>
<p>这时候，绿色区域已经确定了，相当于V中对应坐标$(x^t_i, y_i^t)$  的像素都将从U中这块绿色区域中获取。 $H’,W’$ 与$H,W$   不一定相等；即便是相等，由于变换后的源坐标  $(x^s_i, y_i^s)$ 很有可能不是整数 ，对应U中不是整数像素点，所以没有像素值，没办法直接拷贝。所以V中  $(x^t_i, y_i^t)$ 坐标的像素值如何确定就成了问题。这时就涉及到采样和插值。</p>
<h2 id="2-3-Sampler"><a href="#2-3-Sampler" class="headerlink" title="2.3 Sampler"></a>2.3 Sampler</h2><p>实际上 CNN中的卷积核 或者 池化核起到的就是采样的作用。</p>
<p>$(x^s_i, y_i^s)$ 是U中绿色区域的坐标，来看看更加具有一般性的采样问题如何描述：</p>
<p><img src="/articles/7c7952f0/1517398970784.png" alt="1517398970784"></p>
<ul>
<li>$U_{nm}^c$ 是输入feature map上第 $c$ 个通道上坐标为 $(n, m)$ 的像素值；</li>
<li>$V_i^c$ 是输出 feature map上第 $c$ 个通道上坐标为 $(x^t_i, y_i^t)$ 的像素值；</li>
<li>$k()$ 表示插值核函数；</li>
<li>$Φx , Φy$  代表 x 和 y 方向的插值核函数的参数；</li>
<li>$H,W$ 输入U的尺寸;</li>
<li>$H’,W’$ 输出 V 的尺寸;</li>
</ul>
<p>注意上式只是针对一个通道的像素进行采样，实际上每个通道的采样都是一样的，这样可以保留 空间一致性。</p>
<p>卷积的操作也是符合上式的，比如一维卷积：</p>
<p><img src="/articles/7c7952f0/1517400545429.png" alt="1517400545429"></p>
<ul>
<li>$f(\tau)$ 相当于 $U_{nm}^c$ ；</li>
<li>$g(n-\tau)$ 相当于 $k(x_i^s-m; \Phi_x)$ 或 $(y_i^s-m; \Phi_y)$   因为这里的卷积是 一维的。</li>
</ul>
<p>理论来说 任意 对 $x^s_i, y_i^s$ 可导或局部可导的采样核函数都是可以使用的.</p>
<p>比如最近邻插值核函数:</p>
<p><img src="/articles/7c7952f0/1517401679000.png" alt="1517401679000"></p>
<ul>
<li>其中<img src="/articles/7c7952f0/1517401798196.png" alt="1517401798196"></li>
<li>$\lfloor x + 0.5\rfloor$ 向下取整</li>
</ul>
<p>这个插值核函数做的就是把U中 离 当前源坐标 $(x^s_i, y_i^s)$ （小数坐标） 最近的 整数坐标 $(n,m)$ 处的像素值拷贝到V中的  $(x^t_i, y_i^t)$ 坐标处；</p>
<p>不过这篇文章使用的是双线性插值，双线性插值 参考 <a href="https://zh.wikipedia.org/wiki/%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC" target="_blank" rel="external">维基百科</a> 和 <a href="http://blog.csdn.net/lz0499/article/details/69791572" target="_blank" rel="external">图像处理之插值运算</a>，这里放一张示意图吧：</p>
<p><img src="/articles/7c7952f0/20170403231241311.png" alt="20170403231241311"></p>
<center> <strong>图4 双线性插值（来源于[参考资料 6]）</strong></center>



<p>这里的公式如下：</p>
<p><img src="/articles/7c7952f0/1517402932968.png" alt="1517402932968"></p>
<p>这个插值核函数做的是利用 U中 离 当前源坐标 $(x^s_i, y_i^s)$ （小数坐标）  最近的 4个整数坐标 $(n,m)$ 处的像素值做双线性插值然后拷贝到V中的  $(x^t_i, y_i^t)$ 坐标处；</p>
<p>我在想他那个通过仿射变换确定绿色区域之后，绿色区域相当于ROI，那采样能不能使用ROI 池化的方式?</p>
<h2 id="2-4-前向传播"><a href="#2-4-前向传播" class="headerlink" title="2.4 前向传播"></a>2.4 前向传播</h2><p>结合前面的分析，总结一下前向传播的过程，如下图：</p>
<ul>
<li>实际上首先进行的是 localisation network 的回归，产生 变换矩阵的参数 $\theta$ ，进而resize为 变换矩阵 $T_{\theta}$ ;</li>
<li>根据 V中的 目标坐标 $(x^t_i, y_i^t)$ 做逆向仿射变换变换到源坐标  $(x^s_i, y_i^s)$ ： $Source= T_{\theta} \cdot Target$ ， 源坐标 $(x^s_i, y_i^s)$ 位于U上；对应图中 1,2步；</li>
<li>在U中找到 源坐标 $(x^s_i, y_i^s)$ （小数坐标）附近的四个整数坐标，做双线性插值，插值后的值作为 目标坐标  $(x^t_i, y_i^t)$ 处的像素值；对应图中 3,4步；</li>
</ul>
<p><img src="/articles/7c7952f0/678029-20151022183134552-279360383.png" alt="678029-20151022183134552-279360383"></p>
<center> <strong>图5 前向传播流程</strong>（来源于<strong>[参考资料 6]</strong>）</center>



<h2 id="2-5-梯度流动与反向传播"><a href="#2-5-梯度流动与反向传播" class="headerlink" title="2.5 梯度流动与反向传播"></a>2.5 梯度流动与反向传播</h2><p>这个函数虽不是 完全可导 但也是局部可导的，求导如下，对  $y_i^s$ 的导数也是类似的：</p>
<p><img src="/articles/7c7952f0/1517403846718.png" alt="1517403846718"></p>
<p>根据公式(1)很容易求得： $\dfrac{\partial x_i^s}{\partial \theta}    $   和 $\dfrac{\partial  y_i^s}{\partial \theta} $ 。</p>
<p>所以反向传播过程，误差可以传播到输入 feature map（公式6），可以传播到 采样格点坐标(sampling grid coordinates )（公式7），还可以传播到变换参数 $\theta$ .</p>
<p>下图是梯度流动的示意图：</p>
<p><img src="/articles/7c7952f0/678029-20151023135057427-1219705201.png" alt="678029-20151023135057427-1219705201"></p>
<center> <strong>图6 反向传播流程</strong>（来源于<strong>[参考资料 6]</strong>）</center>

<p>其中localisation network中的 $\dfrac{\partial x_i^s}{\partial \theta}    $   和 $\dfrac{\partial  y_i^s}{\partial \theta} $ 也就是这一股误差流 $\left\{\begin{matrix}\frac{\partial V_{i}^{c}}{\partial x_{i}^{S}}\rightarrow \frac{\partial x_{i}^{S}}{\partial \theta}\ \frac{\partial V_{i}^{c}}{\partial y_{i}^{S}}\rightarrow \frac{\partial y_{i}^{S}}{\partial \theta}\end{matrix}\right.$  ，在定位网络处就断了。</p>
<p>定位网络是一个回归模型，相当于一个子网络，一旦更新完参数，流就断了，独立于主网络。</p>
<h1 id="3-试验"><a href="#3-试验" class="headerlink" title="3 试验"></a>3 试验</h1><h2 id="3-1-Distorted-MNIST"><a href="#3-1-Distorted-MNIST" class="headerlink" title="3.1 Distorted MNIST"></a>3.1 Distorted MNIST</h2><p>这个试验的数据集 是 MNIST，不过与原版的MNIST 不同，这个数据集对图片上的数字做了各种形变操作，比如平移，扭曲，放缩，旋转等。</p>
<p>如下，不同形变操作的简写表示：</p>
<ul>
<li>旋转：rotation (R), </li>
<li>旋转+缩放+平移：rotation, scale and translation (RTS), </li>
<li>投影变换：projective transformation (P), </li>
<li>弹性变形：elastic warping (E) – note that elastic warping is destructive and can not be inverted in some cases.  </li>
</ul>
<p>文章将 Spatial Transformer 模块嵌入到 两种主流的分类网络，FCN和CNN中（ST-FCN 和 ST-CNN ）。Spatial Transformer 模块嵌入位置在图片输入层与后续分类层之间。</p>
<p>试验也测试了不同的变换函数对结果的影响：</p>
<ul>
<li>仿射变换：affine transformation (Aff), </li>
<li>投影变换：projective transformation (Proj),</li>
<li>薄板样条变换：16-point thin plate spline transformation (TPS) </li>
</ul>
<p>其中CNN的模型与 LeNet是一样的，包含两个池化层。为了公平，所有的网络变种都只包含 3 个可学习参数的层，总体网络参数基本一致，训练策略也相同。</p>
<p>试验结果</p>
<p><img src="/articles/7c7952f0/1517407970094.png" alt="1517407970094"></p>
<ul>
<li>左侧：不同的形变策略以及不同的 Spatial Transformer网络变种与 baseline的对比；</li>
<li>右侧：一些CNN分错，但是ST-CNN分对的样本<ul>
<li>(a)：输入</li>
<li>(b)：Spatial Transformer层 的 源坐标（$T_{\theta}(G)$ ）可视化结果 </li>
<li>(c)：Spatial Transformer层输出</li>
</ul>
</li>
<li>很明显：ST-CNN优于CNN, ST-FCN优于FCN，说明Spatial Transformer确实增加了 空间不变性</li>
<li>FCN中由于没有 池化层，所以FCN的空间不变性不如CNN，所以FCN效果不如CNN</li>
<li>ST-FCN效果可以达到CNN程度，说明Spatial Transformer确实增加了 空间不变性</li>
<li>ST-CNN效果优于ST-FCN，说明 池化层 确实对 增加 空间不变性很重要</li>
<li>在 Spatial Transformer 中使用 plate spline transformation (TPS)  变换效果是最好的</li>
<li>Spatial Transformer 可以将歪的数字扭正</li>
<li>Spatial Transformer 在输入图片上确定的attention区域很明显利于后续分类层分类，可以更加有效地减少分类损失</li>
</ul>
<p>作者也做了噪声环境下的试验：将数字 放置在 60×60的图片上，并添加斑点噪声（图1第三行）错误率分别为：</p>
<p> FCN ，13.2% error； CNN ， 3.5% error；  ST-FCN ，2.0% error；  ST-CNN ，1.7% error. </p>
<h2 id="3-2-Street-View-House-Numbers"><a href="#3-2-Street-View-House-Numbers" class="headerlink" title="3.2 Street View House Numbers"></a>3.2 Street View House Numbers</h2><p>Street View House Numbers是一个真实的 街景门牌号 数据集，共200k张图片，每张图片包含1-5个数字 ，数字都有形变。</p>
<ul>
<li>baseline character sequence CNN model ：11层，5个softmax层输出对应位置的预测序列</li>
<li>STCNN Single ：在输入层添加一个Spatial Transformer </li>
<li>ST-CNN Multi ：前四层，每一层都添加一个Spatial Transformer 见下面 tabel 2 右侧</li>
<li>localisation networks 子网络：两层32维的全连接层</li>
<li>使用仿射变换和双线性插值</li>
</ul>
<p>结果：</p>
<p><img src="/articles/7c7952f0/1517409630548.png" alt="1517409630548"></p>
<h2 id="3-3-Fine-Grained-Classification"><a href="#3-3-Fine-Grained-Classification" class="headerlink" title="3.3 Fine-Grained Classification"></a>3.3 Fine-Grained Classification</h2><p>数据集：CUB-200-2011 birds dataset，  6k training images and 5.8k test images, covering 200 species of birds. </p>
<ul>
<li>baseline CNN model ： an Inception architecture with batch normalisation pre-trained on ImageNet and fine-tuned on CUB – which by itself achieves the state-of-the-art accuracy of 82.3% (previous best result is 81.0% [30]).  </li>
<li>ST-CNN, which contains 2 or 4 parallel spatial transformers, parameterised for attention and acting on the input image. </li>
</ul>
<p>这里使用了并行的Spatial Transformer ， 效果是可以将图片的不同 部分（part）输入到不同的 Spatial Transformer 层，会产生不同的 part representations 然后经过 inception ，最后再合并起来，经过一个单独的softmax层做分类。</p>
<p>结果：</p>
<p><img src="/articles/7c7952f0/1517410123817.png" alt="1517410123817"></p>
<ul>
<li>ST-CNN效果最好</li>
<li>右侧上边使用了 2 路 Spatial Transformer并行，可以看到其中一个 spatial transformer(红色) 检测的是鸟的头部, 而另外一个 (绿色) 检测的鸟的身体.  </li>
<li>右侧下边使用了 4 路 Spatial Transformer并行，有相似的效果.</li>
<li>此处的Spatial Transformer有点像目标检测的味道</li>
</ul>
<h2 id="3-4-MNIST-Addition"><a href="#3-4-MNIST-Addition" class="headerlink" title="3.4 MNIST Addition"></a>3.4 MNIST Addition</h2><p>这个试验是将任意两张MNIST中的数字独立的进行一系列变形，然后叠加到一块，给网络识别，标签是二者之和。</p>
<p>同样的测试 FCN, CNN, ST-CNN,2×ST-CNN。</p>
<p>2×ST-CNN在输入层使用了两个并行的Spatial Transformer，结构见下面table 4右侧。</p>
<p><img src="/articles/7c7952f0/1517411239599.png" alt="1517411239599"></p>
<ul>
<li>由于数据比较复杂，FCN的效果很差，添加了 Spatial Transformer之后，错误率显著下降</li>
<li>CNN有池化层存在所以效果比FCN好</li>
<li>2×ST-CNN效果最好</li>
<li>从右边可视化的图中可以看到虽然每个输入channel都输入到了两个Spatial Transformer中，但是每个Spatial Transformer都是对其中一个channel作用强，而且这两个Spatial Transformer是互补的，所以最后连接起来之后 4个通道的feature map中有两个是完整的数字，所以识别较为有效。</li>
</ul>
<h2 id="3-5-Co-localisation"><a href="#3-5-Co-localisation" class="headerlink" title="3.5 Co-localisation"></a>3.5 Co-localisation</h2><p>这个试验将 Spatial Transformer用在了半监督的任务Co-localisation 。</p>
<p>Co-localisation ：给一些图片，假设这些图片包含一些目标（也可能不包含），在不使用目标类别标签和目标位置标签的情况下，定位出常见的目标。</p>
<p>数据集还是 MNIST ，将 28×28大小的 数字图像 随机的放在 84×84 大小的含有噪声的背景上，对每个数字产生100个不同的变形。数据有定位标签，但是在训练时不用，测试时用。</p>
<p>模型还是使用 LeNet CNN模型，在输入层嵌入Spatial Transformer。</p>
<p>文章使用了半监督的方式，监督的学习过程是这样的：</p>
<p>对于一个 包含 N 张图片的 数据集 $I = \{I_n\}$  ，比如table 5 右侧的图。</p>
<ul>
<li>最下面一行代表在同类别的样本中挑选一张 $I_n$ 做一个随机裁剪，裁剪出的这一块 $I_n^{rand}$ ,认为是目标位置</li>
<li>中间这一行代表将同样的样本 $I_n$输入 Spatial Transformer，输出 $I_n^{T}$ </li>
<li>上面这行代表另选一个样本  $I_m$ 输入Spatial Transformer，输出  $I_m^{T}$ </li>
<li>以上三个输出分别经过一个映射函数 $e()$ ，这个函数由 LeNet CNN模型提供，以便于将上述三个feature map映射成向量，映射成向量后可以计算两两之间的距离</li>
<li>计算 $L1=||e(I_m^T)-e(I_n^T)|_2$  , $L2=||e(I_n^T)-e(I_n^{rand})||_2$ , 训练过程中就是要保证 L1 &lt; L2，L2是一个随机裁剪与经过Spatial Transformer的输出之间的距离，理应大于L1.</li>
</ul>
<p><img src="/articles/7c7952f0/1517412959220.png" alt="1517412959220"></p>
<p>经过上面的分析，可以提出如下损失函数: hinge loss (triplet loss)</p>
<p><img src="/articles/7c7952f0/1517414543432.png" alt="1517414543432"></p>
<p>$α$ is a margin ,可以称为 裕度，相当于净赚多少。</p>
<p>半监督是因为这里的标签相当于 L2，而L2是人为构造出来的距离指标。</p>
<p>测试时认为检测出的box与ground truth bounding box的IOU 大于0.5为正确，table5 左侧为测试结果。</p>
<p>在没有噪声时，可以达到100%的准确率，有噪声时在75-93%之间。</p>
<p>下图是优化过程的动态可视化结果，可见随着迭代次数越来越多，模型对目标的定位越来越准确</p>
<p><img src="/articles/7c7952f0/1517414970818.png" alt="1517414970818"></p>
<p>这个试验使用了一种简单的损失函数，在不使用数据定位标签的情况下，构建了一种距离标签，实现了对目标的检测。这个可以推广到目标检测或追踪问题中去。</p>
<p>作者把前面一些检测的动态效果做成了视频，看起来很清晰明了，看这里：<a href="https://goo.gl/qdEhUu" target="_blank" rel="external">https://goo.gl/qdEhUu</a> </p>
<h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h1><p>这篇文章提出的 Spatial Transformer 结构能够很方便的嵌入到现有的CNN模型中去，并且实现端到端（end-to-end）的训练，通过对数据进行反向空间变换来消除图片上目标的变形，从而使得分类网络的识别更加简单高效。现在的CNN的已经非常强大了，但是 Spatial Transformer 仍然能过通过增强空间不变性来提高性能表现。Spatial Transformer实际上是一种attention机制，可以用于目标检测，目标追踪等问题，还可以构建半监督模。</p>
<p>下一篇介绍 Deformable Convolutional Networks ，跟本篇的TSN思路很像，但是又比这个模型简单。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol>
<li><a href="http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.html" target="_blank" rel="external">opencv中文教程——仿射变换</a></li>
<li><a href="https://guangchun.wordpress.com/2011/10/12/affineandhomogeneous/" target="_blank" rel="external">仿射变换与齐次坐标</a></li>
<li><a href="https://www.zhihu.com/question/20666664" target="_blank" rel="external">知乎——如何通俗易懂的理解高维仿射变换与线性变换</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC" target="_blank" rel="external">维基百科——双线性插值</a></li>
<li><a href="http://blog.csdn.net/lz0499/article/details/69791572" target="_blank" rel="external">图像处理之插值运算</a></li>
<li><a href="http://www.cnblogs.com/neopenx/p/4851806.html" target="_blank" rel="external">讲STN的一篇博客，不过关于仿射变换那一块写的是错的，但是其中的图还是挺不错的，借用几张图</a></li>
</ol>

      
    </div>
    
    
    

    
      <div>
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  <!-- JS库 sweetalert 可修改路径 -->
  <script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"></script>
  <script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"></script>
  <link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css">
  <p><strong>本文标题：</strong><a href="/articles/7c7952f0/">基础DL模型-STN-Spatial Transformer Networks-论文笔记</a></p>
  <p><strong>本文作者：</strong><a href="/" title="访问 arleyzhang 的个人博客">arleyzhang</a></p>
  <p><strong>发布时间：</strong>2018年06月05日 - 02:06</p>
  <p><strong>最后更新：</strong>2018年11月16日 - 22:11</p>
  <p><strong>本文链接：</strong><a href="/articles/7c7952f0/" title="基础DL模型-STN-Spatial Transformer Networks-论文笔记">https://arleyzhang.github.io/articles/7c7952f0/</a>
    <span class="copy-path"  title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://arleyzhang.github.io/articles/7c7952f0/"  aria-label="复制成功！"></i></span>
  </p>
  <p><strong>版权声明：</strong> 本文由 arleyzhang 原创，采用 <i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">保留署名-非商业性使用-禁止演绎 4.0-国际许可协议</a>，转载请保留原文链接及作者!</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    clipboard.on('success', $(function(){
      $(".fa-clipboard").click(function(){
        swal({   
          title: "",   
          text: '复制成功',   
          html: false,
          timer: 500,   
          showConfirmButton: false
        });
      });
    }));  
</script>

      </div>
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/basic-dl-models/" rel="tag"><i class="fa fa-tag"></i> basic dl models</a>
          
            <a href="/tags/论文笔记/" rel="tag"><i class="fa fa-tag"></i> 论文笔记</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/articles/21c44637/" rel="next" title="目标检测-从RCNN到Mask RCNN两步检测算法总结">
                <i class="fa fa-chevron-left"></i> 目标检测-从RCNN到Mask RCNN两步检测算法总结
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/articles/a6992dce/" rel="prev" title="基础DL模型-Deformable Convolutional Networks-论文笔记">
                基础DL模型-Deformable Convolutional Networks-论文笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">arleyzhang</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/arleyzhang" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:1186197274@qq.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-简介"><span class="nav-text">1 简介</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-问题提出"><span class="nav-text">1.2 问题提出</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-解决方法"><span class="nav-text">1.2 解决方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Spatial-Transformer结构"><span class="nav-text">2 Spatial Transformer结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Localisation-network"><span class="nav-text">2.1 Localisation network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-Grid-generator"><span class="nav-text">2.2 Grid generator</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-Sampler"><span class="nav-text">2.3 Sampler</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-前向传播"><span class="nav-text">2.4 前向传播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-梯度流动与反向传播"><span class="nav-text">2.5 梯度流动与反向传播</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-试验"><span class="nav-text">3 试验</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Distorted-MNIST"><span class="nav-text">3.1 Distorted MNIST</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-Street-View-House-Numbers"><span class="nav-text">3.2 Street View House Numbers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-Fine-Grained-Classification"><span class="nav-text">3.3 Fine-Grained Classification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-MNIST-Addition"><span class="nav-text">3.4 MNIST Addition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-5-Co-localisation"><span class="nav-text">3.5 Co-localisation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-总结"><span class="nav-text">4 总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考资料"><span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">arleyzhang</span>

  
</div>









        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  

    
      <script id="dsq-count-scr" src="https://arleyzhang.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://arleyzhang.github.io/articles/7c7952f0/';
          this.page.identifier = 'articles/7c7952f0/';
          this.page.title = '基础DL模型-STN-Spatial Transformer Networks-论文笔记';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://arleyzhang.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
